# ðŸ”§ LLM Fine-Tuning Framework (LoRA / QLoRA / Full FT)

This repository provides a flexible, modular framework to fine-tune transformer-based language models (like **Phi-2**, **Mistral**, **LLaMA**, etc.) using:
- âœ… **LoRA** (Low-Rank Adaptation)
- âœ… **QLoRA** (Quantized LoRA for low-VRAM GPUs)
- âœ… **Full fine-tuning** (for large-scale systems)

You can configure everything â€” from which model to use, to what parts of it to adapt/train â€” using YAML configuration files.# Fine-Tuning-Phi-3
This project supports fine-tuning large language models like Phi-2 or Phi-3 using tokenized datasets in HuggingFace format (.arrow). It supports 3 types of inputs:

ðŸ”¤ Raw .txt files
ðŸ“˜ Instruction-style .jsonl files
ðŸ’¬ Chat-style .jsonl files

â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ incoming_text/          # Raw .txt files
â”‚   â”œâ”€â”€ incoming_instruction/   # Instruction .jsonl files
â”‚   â”œâ”€â”€ incoming_chat/          # Chat .jsonl files
â”‚   â””â”€â”€ tokenized/              # Output tokenized datasets (.arrow)
â”‚
â”œâ”€â”€ checkpoints/                # Model checkpoints
â”œâ”€â”€ config/                     # YAML configuration files
â”œâ”€â”€ seen_datasets.json          # Tracks processed files
â”œâ”€â”€ prepare_raw_text_dataset.py
â”œâ”€â”€ prepare_instruction_dataset.py
â”œâ”€â”€ prepare_chat_dataset.py
â”œâ”€â”€ train.py
 Dataset Preparation
1. Prepare from raw .txt
2. python scripts/prepare_raw_text_dataset.py \
  --model_id microsoft/phi-3-mini-4k-instruct \
  --input_dir data/incoming_text/ \
  --output_dir data/tokenized/
1. Prepare from instruction .jsonl
python scripts/prepare_instruction_dataset.py \
  --model_id microsoft/phi-3-mini-4k-instruct \
  --input_dir data/incoming_instruction/ \
  --output_dir data/tokenized/

1. Prepare from chat .jsonl
python prepare_chat_dataset.py \
  --model_id microsoft/phi-3-mini-4k-instruct \
  --input_dir data/incoming_chat/ \
  --output_dir data/tokenized/

ðŸš€ Fine-Tune the Model
After tokenizing, train the model using:
python train.py \
  --train_config config/train_qlora.yaml \
  --model_config config/model_phi3.yaml \
  --experiment_config config/experiment.yaml
